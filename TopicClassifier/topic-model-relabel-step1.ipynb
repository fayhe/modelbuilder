{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from textacy import fileio, preprocess, extract, Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_docs = fileio.read_file_lines('/home/SMRT-labeled/summary-docs')\n",
    "summary_meta = fileio.read_json_lines('/home/SMRT-labeled/summary-meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = [t for t in summary_docs]\n",
    "meta = [m for m in summary_meta][0]\n",
    "\n",
    "corpus_train = Corpus('en', texts = text, metadatas = meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category smrt corporate\n",
      "Topic corporate & financials\n",
      "Tonality neutral\n"
     ]
    }
   ],
   "source": [
    "for k in meta[0]:\n",
    "    print k, meta[0][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topiclist = [t['Topic'] for t in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'commuter behaviour': 16,\n",
       "         u'corporate & financials': 102,\n",
       "         u'corporate social responsibility': 12,\n",
       "         u'crisis / delays & distributions / accidents / safety': 323,\n",
       "         u'csr': 40,\n",
       "         u'customer satisfaction': 5,\n",
       "         u'customer service': 16,\n",
       "         u'delay/disruption': 85,\n",
       "         u'facilities': 24,\n",
       "         u'facilities & services': 264,\n",
       "         u'fares': 13,\n",
       "         u'financials': 42,\n",
       "         u'fines': 3,\n",
       "         u'general / others': 153,\n",
       "         u'labour': 31,\n",
       "         u'labour & union': 101,\n",
       "         u'rail & engineering': 264,\n",
       "         u'regulations': 23,\n",
       "         u'regulations & ops': 25,\n",
       "         u'repair/maintenance': 25,\n",
       "         u'safety/accident': 45,\n",
       "         u'service announcements': 40,\n",
       "         u'service excellence': 37,\n",
       "         u'unknown': 77})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(topiclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "filter_a = [(i == u'crisis / delays & distributions / accidents / safety') for i in topiclist]\n",
    "filter_b = [(i == u'delay/disruption') for i in topiclist]\n",
    "filter_c = [(i == u'safety/accident') for i in topiclist]\n",
    "\n",
    "filter_combine = map(lambda x:(x[0] or x[1]), zip(filter_b, filter_c))\n",
    "#filter_combine.count(True)\n",
    "\n",
    "text_train_filter = [x[0] for x in zip(text, filter_combine) if x[1]]\n",
    "meta_train_filter = [x[0] for x in zip(topiclist, filter_combine) if x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textacy import vsm\n",
    "\n",
    "corpus_train_filter = Corpus('en', texts = text_train_filter, metadatas = meta_train_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#topic model\n",
    "terms_lists = (doc.to_terms_list(ngrams={1, 2}, named_entities=True, as_strings=True) for doc in corpus_train_filter)\n",
    "doc_term_matrix, id2term = vsm.doc_term_matrix(terms_lists, weighting='tf', normalize=True, smooth_idf=True, min_df=1, max_df=0.75, max_n_terms=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<130x6158 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 14318 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load lable data\n",
    "label_key = u'Category'\n",
    "\n",
    "label_list = meta_train_filter\n",
    "unique_label = list(set(label_list))\n",
    "label2id = dict(zip(unique_label, range(len(unique_label))))\n",
    "label_id = map(lambda x:label2id[x], label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'delay/disruption': 0, u'safety/accident': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation=u'logistic', alpha=1e-05, batch_size=10, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver=u'adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLPClassifier requires sklearn >=0.18\n",
    "#classifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#use sknn instead\n",
    "#from sknn.mlp import Classifier, Layer\n",
    "import numpy as np\n",
    "\n",
    "def id2array(id, a_len):\n",
    "    result = np.zeros(a_len)\n",
    "    result[id] = 1\n",
    "    return result\n",
    "\n",
    "labeltype = len(label2id.keys())\n",
    "\n",
    "msg_x = doc_term_matrix.toarray()\n",
    "msg_y = np.array([id2array(x, labeltype) for x in label_id])\n",
    "\n",
    "clf = MLPRegressor(activation='logistic', solver='adam', alpha=1e-5, batch_size=10, hidden_layer_sizes=(50, ), random_state=1)\n",
    "clf.fit(msg_x, msg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99765301098971648"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(msg_x, msg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re-labelling unlabelled data\n",
    "text_test_filter = [x[0] for x in zip(text, filter_a) if x[1]]\n",
    "corpus_test = Corpus('en', texts = text_test_filter)\n",
    "\n",
    "terms_lists_test = (doc.to_terms_list(ngrams={1, 2}, named_entities=True, as_strings=True) for doc in corpus_test)\n",
    "dtm_test, i2t_test = vsm.doc_term_matrix(terms_lists_test, weighting='tf', normalize=True, smooth_idf=True, min_df=1, max_df=0.75, max_n_terms=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build new index\n",
    "test2train = dict()\n",
    "for (i, j) in i2t_test.items():\n",
    "    if j in id2term.values():\n",
    "        train_i = id2term.keys()[id2term.values().index(j)]\n",
    "        test2train[i]=train_i\n",
    "\n",
    "test_feature = np.zeros((dtm_test.shape[0], len(id2term)))\n",
    "dtm_test_array = dtm_test.toarray()\n",
    "\n",
    "for (i, j) in test2train.items():\n",
    "    test_feature[:, j] = dtm_test_array[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_label = clf.predict(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('re-label-output', 'wb') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for i_row in zip(text_test_filter, auto_label): \n",
    "        wr.writerow(i_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'delay/disruption': 0, u'safety/accident': 1}\n"
     ]
    }
   ],
   "source": [
    "#amend original meta\n",
    "print(label2id)\n",
    "\n",
    "def assignNewLabel(v):\n",
    "    tmpv = v[0] - v[1]\n",
    "    if(abs(tmpv) <= 0.1):\n",
    "        return u'crisis'\n",
    "    elif(tmpv>0.0):\n",
    "        return label2id.keys()[label2id.values().index(0)]\n",
    "    else:\n",
    "        return label2id.keys()[label2id.values().index(1)]\n",
    "\n",
    "new_label = map(assignNewLabel, auto_label)\n",
    "#filter_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_label_index = [x[0] for x in zip(range(len(filter_a)), filter_a) if x[1]]\n",
    "for i in zip(new_label, new_label_index):\n",
    "    meta[i[1]]['Topic'] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textacy import fileio\n",
    "\n",
    "fileio.write_json(meta, '/home/SMRT-labeled/summary-meta-relabel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
