{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_raw = json.load(open('../dict/vocab_list.json', 'r'))\n",
    "\n",
    "#clean _num_ \n",
    "num_keys = [i for i in vocab_raw.keys() if (i.find('_num_') != -1)]\n",
    "for i in num_keys:\n",
    "    vocab_raw.pop(i)\n",
    "\n",
    "#new key list\n",
    "vocab_keys = [u'_num_']\n",
    "vocab_keys.extend(vocab_raw.keys())\n",
    "\n",
    "#reserve index 0: padding, index 1: _num_\n",
    "vocab_dict = {k:v for k, v in zip(vocab_keys, range(2, len(vocab_keys)+2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: u'NaN', 1: u'INTERCHANGE', 2: u'SERVICE', 3: u'TITLE', 4: u'DATE', 5: u'STATION', 6: u'DURATION', 7: u'LINE', 8: u'AREA', 9: u'BUS', 10: u'LOCATION', 11: u'ROAD', 12: u'GNUM', 13: u'PERCENT', 14: u'O', 15: u'DEPOT', 16: u'PRODUCT', 17: u'NORP', 18: u'MONEY', 19: u'PERSON', 20: u'TIME', 21: u'ORG', 22: u'EVENT'}\n"
     ]
    }
   ],
   "source": [
    "entity_raw = json.load(open('./Model/entityDict.json', 'r'))\n",
    "\n",
    "int2entity_ = {v:k for k, v in entity_raw.items()}\n",
    "\n",
    "int2entity = lambda x:int2entity_[x]\n",
    "int2entity(1)\n",
    "print(int2entity_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'ADV': 1, u'NOUN': 2, u'NUM': 11, u'ADP': 3, u'PRON': 4, u'DET': 6, u'PROPN': 5, u'NaN': 0, u'SYM': 7, u'INTJ': 8, u'PUNCT': 10, u'PART': 9, u'X': 12, u'CONJ': 13, u'ADJ': 14, u'VERB': 15}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "pos_raw = json.load(open('./Model/posDict.json', 'r'))\n",
    "print(pos_raw)\n",
    "int2pos_ = {v:k for k, v in pos_raw.items()}\n",
    "\n",
    "int2pos = lambda x:int2pos_[x]\n",
    "int2pos(1)\n",
    "\n",
    "\n",
    "pos2int_ = {k:v for k, v in pos_raw.items()}\n",
    "print(pos2int_['ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2063)\n"
     ]
    }
   ],
   "source": [
    "def word2Int(wd):\n",
    "    try:\n",
    "        return(vocab_dict[wd])\n",
    "    except KeyError:\n",
    "        return 1\n",
    "\n",
    "print(word2Int(u'nuk'), word2Int(u'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contextwin(l, win):\n",
    "    '''\n",
    "    win :: int corresponding to the size of the window\n",
    "    given a list of indexes composing a sentence\n",
    "\n",
    "    l :: array containing the word indexes\n",
    "\n",
    "    it will return a list of list of indexes corresponding\n",
    "    to context windows surrounding each word in the sentence\n",
    "    '''\n",
    "    assert (win % 2) == 1\n",
    "    assert win >= 1\n",
    "    l = list(l)\n",
    "\n",
    "    lpadded = win // 2 * [-1] + l + win // 2 * [-1]\n",
    "    out = [lpadded[i:(i + win)] for i in range(len(l))]\n",
    "\n",
    "    assert len(out) == len(l)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textacy import Doc, preprocess\n",
    "\n",
    "input_text = u'In 2016 trains travelled an average 174000 trainkilometres between delays of more than five minutes up'\n",
    "\n",
    "test_text = Doc(preprocess.replace_numbers(input_text, replace_with='_num_'))\n",
    "tag_list = [pos2int_[tag[1]] for tag in  test_text.pos_tagged_text[0]]\n",
    "array_text = [word2Int(i.lemma_) for i in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 3\n",
    "TEST_X = contextwin(array_text, maxlen)\n",
    "TEST_P = contextwin(tag_list, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 3, 14],\n",
       " [3, 14, 2],\n",
       " [14, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 15],\n",
       " [2, 15, 6],\n",
       " [15, 6, 14],\n",
       " [6, 14, 14],\n",
       " [14, 14, 2],\n",
       " [14, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 3],\n",
       " [2, 3, 2],\n",
       " [3, 2, 3],\n",
       " [2, 3, 14],\n",
       " [3, 14, 3],\n",
       " [14, 3, 11],\n",
       " [3, 11, 2],\n",
       " [11, 2, 9],\n",
       " [2, 9, -1]]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 457, 1],\n",
       " [457, 1, 1],\n",
       " [1, 1, 1],\n",
       " [1, 1, 2063],\n",
       " [1, 2063, 135],\n",
       " [2063, 135, 2382],\n",
       " [135, 2382, 992],\n",
       " [2382, 992, 1],\n",
       " [992, 1, 1],\n",
       " [1, 1, 1],\n",
       " [1, 1, 1],\n",
       " [1, 1, 1050],\n",
       " [1, 1050, 2101],\n",
       " [1050, 2101, 2073],\n",
       " [2101, 2073, 1420],\n",
       " [2073, 1420, 943],\n",
       " [1420, 943, 2464],\n",
       " [943, 2464, 683],\n",
       " [2464, 683, 1917],\n",
       " [683, 1917, -1]]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def loadModel():\n",
    "    loadfile = open(\"./Model/model-keras1.json\", 'r')\n",
    "    model = model_from_json(loadfile.read())\n",
    "    model.load_weights(\"./Model/model-keras1.h5\")\n",
    "    return model\n",
    "\n",
    "ner_model = loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3 14]\n",
      " [ 3 14  2]\n",
      " [14  2  2]\n",
      " [ 2  2  2]\n",
      " [ 2  2 15]\n",
      " [ 2 15  6]\n",
      " [15  6 14]\n",
      " [ 6 14 14]\n",
      " [14 14  2]\n",
      " [14  2  2]\n",
      " [ 2  2  2]\n",
      " [ 2  2  3]\n",
      " [ 2  3  2]\n",
      " [ 3  2  3]\n",
      " [ 2  3 14]\n",
      " [ 3 14  3]\n",
      " [14  3 11]\n",
      " [ 3 11  2]\n",
      " [11  2  9]\n",
      " [ 2  9  0]]\n",
      "(In, u'O') (2016, u'O') (trains, u'O') (travelled, u'O') (an, u'O') (average, u'O') (174000, u'O') (trainkilometres, u'O') (between, u'O') (delays, u'O') (of, u'O') (more, u'O') (than, u'O') (five, u'O') (minutes, u'O') (up, u'O')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#print(map(lambda x:x.append('haha'),TEST_X))\n",
    "#print(TEST_X)\n",
    "TEST_X_NP = np.array(TEST_X)\n",
    "\n",
    "TEST_X_NP[TEST_X_NP == -1] = 0\n",
    "##print(TEST_X_NP.shape)\n",
    "#print(dir(ner_model))\n",
    "\n",
    "POS = np.array(TEST_P)\n",
    "POS[POS == -1] = 0\n",
    "print(POS)\n",
    "v = ner_model.predict({'word_input':TEST_X_NP,'pos_input':POS})\n",
    "\n",
    "##print(int2entity_[0])\n",
    "predicted_entity_id = v.argmax(axis=1)\n",
    "predicted_entity = [int2entity_[x] for x in predicted_entity_id]\n",
    "for i in zip(Doc(input_text), predicted_entity):\n",
    "    print i,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
